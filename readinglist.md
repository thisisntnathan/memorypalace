---
layout: article
title: Reading List
nav_key: toread
aside:
  toc: true
key: page-readlist
mathjax: true
mathjax_autoNumber: false
---

Like a todo-list but for knowledge. Ideally this page is auto-updated by the curating agent every morning as it reads the arXiv feeds...  


## 17 Jan 2025  



## 15 Jan 2025  

- [How Local is `Local'? Deep Learning Reveals Locality of the Induced Magnetic Field of Polycyclic Aromatic Hydrocarbons](https://dx.doi.org/10.26434/chemrxiv-2025-pqmcc?rft_dat=source%3Ddrss)  
Renana Gershoni-Poranne, Yair Davidson, Aviad Philipp, Sabyasachi Chakraborty, Alex M. Bronstein  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-14  
&ensp;The paper explores the locality of the magnetic response in polycyclic aromatic hydrocarbons using graph neural networks (GNNs). Trained on datasets with varying sizes of molecules, the models maintain high accuracy (MAE < 0.5 ppm) even with 15-ring molecules. The study demonstrates an effective k-hop expansion strategy, aiding in overcoming GNN generalization and enhancing molecule characterization efficiency.

- [ACES-GNN: Can Graph Neural Network Learn to Explain Activity Cliffs?](https://dx.doi.org/10.26434/chemrxiv-2025-11wfv?rft_dat=source%3Ddrss)  
Xu, Chen; Dazhou, Yu; Liang , Zhao; Fang , Liu  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-14  
&ensp;The paper presents ACES-GNN, a Graph Neural Network framework designed to enhance predictive accuracy and interpretability in drug discovery by incorporating explanation supervision for activity cliffs. Tested on 30 pharmacological targets, ACES-GNN outperforms baseline methods in both prediction and explanation quality, addressing challenges of "intra-scaffold" generalization and promoting interpretable AI in molecular modeling.  

- [How Local is `Local'? Deep Learning Reveals Locality of the Induced Magnetic Field of Polycyclic Aromatic Hydrocarbons](https://dx.doi.org/10.26434/chemrxiv-2025-pqmcc?rft_dat=source%3Ddrss)  
Renana, Gershoni-Poranne; Yair, Davidson; Aviad, Philipp; Sabyasachi, Chakraborty; Alex M., Bronstein  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-14  
&ensp;The paper explores the locality of magnetic response in polycyclic aromatic hydrocarbons using graph neural networks (GNNs) with a graph-of-rings representation. It demonstrates high prediction accuracy (MAE < 0.5 ppm) despite training on smaller molecules and employs a k-hop expansion strategy for scalability. The findings suggest efficient magnetic characterization without expensive DFT calculations.  


## 07 Jan 2025  

- [Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts](https://arxiv.org/abs/2501.02009)  
Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper investigates the relationships between concept representations in different Large Language Models (LLMs) using a linear transformation method. Key findings include effective alignment of concept representations across LLMs, generalizability of this alignment, and a weak-to-strong transferability from smaller to larger LLMs for behavioral control through steering vectors.  

- [Safeguarding Large Language Models in Real-time with Tunable Safety-Performance Trade-offs](https://arxiv.org/abs/2501.02018)  
Joao Fonseca, Andrew Bell, Julia Stoyanovich  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents SafeNudge, a novel safeguard for Large Language Models (LLMs) that mitigates jailbreak attacks by utilizing Controlled Text Generation and nudging during text generation. SafeNudge reduces successful jailbreak attempts by 30% with minimal latency and negligible impact on output fluency. It offers tunable Safety-Performance Trade-offs and is open-source for Hugging Face models.  

- [Enhancing Uncertainty Modeling with Semantic Graph for Hallucination Detection](https://arxiv.org/abs/2501.02020)  
Kedi Chen, Qin Chen, Jie Zhou, Xinqi Tao, Bowen Ding, Jingwen Xie, Mingchen Xie, Peilong Li, Feng Zheng, Liang He  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents a method to improve hallucination detection in Large Language Models (LLMs) by enhancing uncertainty modeling with a semantic graph. The approach constructs a semantic graph to capture relations among tokens and sentences, enabling better uncertainty propagation and calibration. Experiments on two datasets demonstrate significant improvements, achieving a 19.78% increase in passage-level hallucination detection accuracy.  

- [Recursive Decomposition of Logical Thoughts: Framework for Superior Reasoning and Knowledge Propagation in Large Language Models](https://arxiv.org/abs/2501.02026)  
Kaleem Ullah Qasim, Jiashu Zhang, Tariq Alsahfi, Ateeq Ur Rehman Butt  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents RDoLT, a new framework for enhancing reasoning in Large Language Models by recursively decomposing tasks, selecting promising thoughts, and integrating knowledge propagation. Evaluated on benchmarks like GSM8K and SVAMP, RDoLT achieved a 90.98% accuracy on GSM8K with ChatGPT-4, outperforming existing methods by 6.28%, demonstrating significant improvements in reasoning capabilities.  

- [CarbonChat: Large Language Model-Based Corporate Carbon Emission Analysis and Climate Knowledge Q&A System](https://arxiv.org/abs/2501.02031)  
Zhixuan Cao, Ming Han, Jingtao Wang, Meng Jia  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents CarbonChat, a Large Language Model-based system for analyzing corporate carbon emissions and answering climate-related queries. It introduces a diversified index module for document segmentation and structured data extraction, an enhanced retrieval-augmented generation architecture, and a framework for carbon emission analysis across 14 dimensions. The approach improves accuracy, reduces hallucination rates, and enhances response precision.  

- [An Investigation into Value Misalignment in LLM-Generated Texts for Cultural Heritage](https://arxiv.org/abs/2501.02039)  
Fan Bu, Zheng Wang, Siyi Wang, Ziyao Liu  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper investigates value misalignment in texts generated by Large Language Models (LLMs) related to cultural heritage. It evaluates 1066 query tasks across five LLMs, finding that over 65% of generated texts exhibit significant cultural misalignments. The study introduces a benchmark dataset and evaluation workflow to improve LLM cultural sensitivity and reliability.  

- [Advancing Pancreatic Cancer Prediction with a Next Visit Token Prediction Head on top of Med-BERT](https://arxiv.org/abs/2501.02044)  
Jianping He, Laila Rasmy, Degui Zhi, Cui Tao  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents a method for improving pancreatic cancer prediction using Med-BERT by reformulating the prediction task into token prediction formats. Utilizing datasets of 10 to 500 samples, the new methods, Med-BERT-Sum and Med-BERT-Mask, outperformed traditional binary classification by 3% to 7% in few-shot scenarios, enhancing accuracy and potential patient outcomes.  

- [AGGA: A Dataset of Academic Guidelines for Generative AI and Large Language Models](https://arxiv.org/abs/2501.02063)  
Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, Amit Dhurandhar  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents AGGA, a dataset of 80 academic guidelines on Generative AIs and Large Language Models, containing 188,674 words sourced from diverse global universities. It facilitates natural language processing tasks like model synthesis and ambiguity detection, providing a comprehensive resource for academia's integration of GAIs and LLMs across various fields and institution types.  

- [The interplay between domain specialization and model size: a case study in the legal domain](https://arxiv.org/abs/2501.02068)  
Roseval Malaquias Junior, Ramon Pires, Thales Sales Almeida, Kenzo Sakiyama, Roseli Romero, Rodrigo Nogueira  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper investigates the relationship between domain specialization and model size in legal language models during continual pre-training. Using a filtered web-based legal dataset, models with varying sizes (1.5B to 14B parameters) were pre-trained and evaluated on legal exams. Results indicate that larger models exhibit a widening compute-effectiveness gap when specialized compared to general models.  

- [Instruction-Following Pruning for Large Language Models](https://arxiv.org/abs/2501.02086)  
Bairu Hou, Qibin Chen, Jianyu Wang, Guoli Yin, Chong Wang, Nan Du, Ruoming Pang, Shiyu Chang, Tao Lei  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper proposes "instruction-following pruning," a dynamic structured pruning method for large language models (LLMs). It utilizes a sparse mask predictor that adapts based on user instructions, optimizing both the predictor and the LLM using instruction-following data. Results show that a 3B activated model outperforms a 3B dense model by 5-8 points in specific domains, matching a 9B model's performance.  

- [Applying Text Mining to Analyze Human Question Asking in Creativity Research](https://arxiv.org/abs/2501.02090)  
Anna Wr\'oblewska, Marceli Korbin, Yoed N. Kenett, Daniel Dan, Maria Ganzha, Marcin Paprzycki  
*cs.CL on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper explores the role of question asking in creativity research using text mining methods to analyze question type, complexity, and answer content. It summarizes the history of question mining and applies natural language processing to five datasets, revealing insights into the cognitive potential of questions in supporting creative ideation.  

- [Coherent signal detection in the statistical polarization regime enables high-resolution nanoscale NMR spectroscopy](https://arxiv.org/abs/2501.02093)  
Nick R. von Grafenstein, Karl D. Briegel, Jorge Casanova, Dominik B. Bucher  
*physics.bio-ph on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper analyzes approximately 3,500 brain cells from various species (mouse, rat, monkey, and human) to derive statistical distributions of morphological features relevant for gray matter microstructure modeling in diffusion-weighted MRI (dMRI). The findings aim to improve biophysical modeling and data acquisition strategies, addressing challenges in accurately characterizing brain microstructure.  

- [Decoding Gray Matter: large-scale analysis of brain cell morphometry to inform microstructural modeling of diffusion MR signals](https://arxiv.org/abs/2501.02100)  
Charlie Aird-Rossiter, Hui Zhang, Daniel C. Alexander, Derek K. Jones, Marco Palombo  
*physics.bio-ph on arXiv*  
Tue, 07 Jan 2025 00:00:00 -0500  
&ensp;The paper presents a method for high-resolution nanoscale NMR spectroscopy using nitrogen-vacancy (NV) centers in diamond. By detecting coherent signals from a uniformly polarized nanoscale sample, it achieves single-digit hertz spectral resolution, overcoming previous limitations. This advancement allows for the resolution of scalar couplings and opens avenues for studying interfaces and single molecules.  



- [A Robust Crystal Structure Prediction Method to Support Small Molecule Drug Development with Large Scale Validation and Prospective Studies](https://dx.doi.org/10.26434/chemrxiv-2024-f17zp-v3?rft_dat=source%3Ddrss)  
Leif Jacobson, Dong Zhou, Imanuel Bier, Biswajit Santra, Chuanjie Wu, Haoyu Yu, Robert Abel, Richard Friesner, Lingle Wang, Adiran Suarez, Barbara Almaguer  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-06  
&ensp;The paper presents a robust crystal structure prediction (CSP) method that combines systematic crystal packing search algorithms with machine learning force fields. Validated on a dataset of 66 molecules and 137 polymorphic forms, it accurately predicts known and suggests new low energy polymorphs. The method enhances drug development by improving formulation design and reducing risks, as demonstrated in a blinded study.  
- [Designing A Bioinspired Degradation System for Forever Chemicals in Water Using Molecular Simulations](https://dx.doi.org/10.26434/chemrxiv-2025-tm6js?rft_dat=source%3Ddrss)  
Danny Nguyen, Jesus Valdiviezo  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-06  
&ensp;The paper proposes using the fatty acid photodecarboxylase (5NCC) enzyme to degrade PFAS, or 'forever chemicals,' which resist natural biodegradation. Molecular simulations, including HOMO, LUMO, and MD, were conducted to assess the enzyme's binding affinity with PFAS. This approach aims to develop a sustainable method for addressing PFAS contamination, overcoming inefficiencies in existing degradation methods.  
- [Periodicity-aware deep learning for polymers](https://dx.doi.org/10.26434/chemrxiv-2025-g2mbp?rft_dat=source%3Ddrss)  
Yuhui Wu, Cong Wang, Xintian Shen, Tianyi Zhang, Peng Zhang, Jian Ji  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-06  
&ensp;The paper presents PerioGT, a periodicity-aware deep learning framework for polymers that incorporates a chemical knowledge-driven periodicity prior through contrastive learning. It employs a novel graph augmentation strategy and achieves state-of-the-art results on 12 tasks. Additionally, wet-lab experiments identify two antimicrobial polymers, showcasing the framework's practical applications and improved performance due to periodicity considerations.  
- [A novel bottom-up approach to find lead-compounds in billion-sized libraries](https://dx.doi.org/10.26434/chemrxiv-2025-lph6p?rft_dat=source%3Ddrss)  
Jordi Juárez-Jiménez, Xavier Barril, Álvaro Serrano-Morrás, Andrea Bertran-Mostazo, Marina Miñarro-Lleonar, Arnau Comajuncosa-Creus, Adrià Cabello, Carme Labranya, Carmen Escudero, Tian Tian, Inna Khutorianska, Dmytro S. Radchenko, Yurii S. Moroz, Lucas Defelipe, David Ruiz-Carrillo, Maria Garcia-Alai, Robert Schmidt, Matthias Rarey, Patrick Aloy, Carles Galdeano  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-06  
&ensp;The paper presents a novel bottom-up approach for identifying lead compounds in vast chemical libraries, specifically trillion-scale on-demand collections. The method involves a systematic exploration of fragment space followed by focused mining of promising areas, utilizing advanced computational techniques to reduce false positives. This strategy successfully identified new BRD4 (BD1) binders with potency comparable to established drugs.  
- [Is BigSMILES the Friend of Polymer Machine Learning?](https://dx.doi.org/10.26434/chemrxiv-2024-bxxhh-v5?rft_dat=source%3Ddrss)  
Haoke Qiu, Zhao-Yan Sun  
*Theoretical and Computational Chemistry on ChemRxiv*  
2025-01-06  
&ensp;The paper evaluates the performance of BigSMILES versus SMILES in polymer machine learning across 12 tasks using convolutional neural networks (CNNs). It highlights that while SMILES is simple, it struggles with polymers, whereas BigSMILES offers a more effective representation. The study aims to determine which representation enhances polymer ML tasks, particularly in property prediction and inverse design.  


## 03 Jan 2025  

- [A Data-Driven Reaction Discovery Strategy Based on Large Language Models](https://dx.doi.org/10.26434/chemrxiv-2025-pnjg7?rft_dat=source%3Ddrss)  
Jingyang, Zhang  
*ChemRxiv*  
2025-01-03  
&ensp;The paper presents a data-driven strategy for discovering novel reactions in organic synthesis by integrating high-throughput experimentation (HTE) with large language models (LLMs). Analyzing 520 publications on cross-electrophile coupling (XEC), the method identifies unexplored substrate pairs and enhances reaction design, demonstrating the effectiveness of combining LLMs with HTE for systematic chemical innovation.  

- [LEGOLAS: a Machine Learning method for rapid and accurate predictions of protein NMR chemical shifts](https://dx.doi.org/10.26434/chemrxiv-2025-w2qn8?rft_dat=source%3Ddrss)  
Adrian Roitberg, Mikayla Darrows, Dimuthu Kodituwakku, Jinze Xue, Nicholas Terrel, Ignacio Pickering  
*ChemRxiv*  
2025-01-03  
&ensp;LEGOLAS is an open-source machine learning model that predicts protein NMR chemical shifts for backbone atoms quickly and accurately. It achieves root-mean-square errors of 2.69 ppm for N and 0.29 ppm for H, outperforming the SHIFTX2 model by a factor of ten. The model enhances predictions using multiple frames from molecular dynamics, improving experimental agreement and recognizing native protein states from decoys.  

- [Revealing the Photochemical Pathways of Nitrate in Water through First-Principles Simulations](https://dx.doi.org/10.26434/chemrxiv-2025-lrx59?rft_dat=source%3Ddrss)  
Davide Donadio, Margaret Berrens, Zekun Chen, C. William McCurdy, Cort Anastasio, Kam-Tung Chan  
*ChemRxiv*  
2025-01-03  
&ensp;The paper investigates the photochemical pathways of nitrate (NO3-) in water using first-principles molecular dynamics simulations with hybrid DFT. It identifies two photolysis channels and explains the low quantum yield (~1%) through spin-forbidden absorption. The study highlights a metastable solvation cage state and temperature dependence, providing insights for future nitrate photochemistry research.  

- [On the Role of α-Alumina in the Origin of Life: Surface Driven Assembly of Amino Acids](https://dx.doi.org/10.26434/chemrxiv-2024-qjq83-v2?rft_dat=source%3Ddrss)  
Ruiyu Wang, Richard C. Remsing, Michael L. Klein, Eric Borguet, Vincenzo Carnevale  
*ChemRxiv*  
2025-01-03  
&ensp;The paper explores how α-alumina surfaces facilitate amino acid self-assembly, crucial for peptide formation. Using molecular dynamics simulations, it finds a 4 kBT affinity for glycine molecules at the α-alumina (0001) surface, enhancing chain formation by over 5 orders of magnitude compared to bulk conditions. The study highlights the role of surface interactions in biochemical assembly processes.  

- [Targeted Molecular Generation With Latent Reinforcement Learning](https://dx.doi.org/10.26434/chemrxiv-2024-8k8gr-v2?rft_dat=source%3Ddrss)  
Ragy Haddad, Eleni Litsa, Zhen Liu, Xin Yu, Daniel Burkhardt, Govinda Bhisetti  
*ChemRxiv*  
2025-01-03  
&ensp;The paper presents a novel approach for targeted molecular generation using Reinforcement Learning with proximal policy optimization (PPO) in the latent space of pre-trained deep learning generative models. The method shows superior performance on benchmark datasets and can generate molecules with specific substructures while optimizing for desired properties, aiding drug discovery.  

- [Unconventional Nonlinear Hall Effects in Twisted Multilayer 2D Materials](https://dx.doi.org/10.26434/chemrxiv-2024-lqvsb-v2?rft_dat=source%3Ddrss)  
Bryan Wong, Mahmut Okyay, Min Choi, Qiang Xu, Adrian Dieguez, Mauro Del Ben, Khaled Ibrahim  
*ChemRxiv*  
2025-01-02  
&ensp;The paper investigates unconventional nonlinear Hall effects in twisted multilayer 2D materials, revealing that stacking order and interlayer interactions significantly influence their optical response. Using Real-Time Time-Dependent Density Functional Theory (RT-TDDFT) and model Hamiltonian analyses, it finds a notable second-harmonic response in four-layer hexagonal boron nitride, challenging existing theories and suggesting new material design possibilities.  

- [A Zero-Shot Single-point Molecule Optimization Model: Mimicking Medicinal Chemists’ Expertise](https://dx.doi.org/10.26434/chemrxiv-2025-m82r5?rft_dat=source%3Ddrss)  
Peng Gao, Jie Zhang, Zhilian Dai, Yangyang Deng, Dan Zhang, Jiawei Fu, Songyou Zhong, Yichao Liu  
*ChemRxiv*  
2025-01-02  
&ensp;The paper presents the Single-point Chemical Language Model (SpCLM), a framework for molecular design that mimics medicinal chemists' expertise. Using a few hundred generated compounds, SpCLM predicts 60%-80% of active compounds in tests, correlating well with experimental data. This method reduces the need for extensive screening, offering a data-driven approach to optimize drug activity and selectivity.  

- [Cost-Efficient Evaluation of Molecular Generative Models' Generalizability in de novo Drug Design via a Double-Parameter Mathematical Framework](https://dx.doi.org/10.26434/chemrxiv-2025-n0qpb?rft_dat=source%3Ddrss)  
PENG GAO, Jie Zhang, Zhilian Dai, Yangyang Deng  
*ChemRxiv*  
2025-01-02  
&ensp;The paper presents a double-parameter mathematical framework to evaluate the generalizability of molecular generative models in drug design efficiently. It proposes three cost-tiered accuracy methods and identifies a unique curve's derivative as a reliable metric. The framework addresses sampling non-uniformity and provides insights into transfer and reinforcement learning effects on model performance, enhancing both theoretical and experimental coverage.  

- [Molecular-Level Characterization of Protein-Nanoparticle Interactions: Orientation, Deformation and Matrix Effects](https://dx.doi.org/10.26434/chemrxiv-2025-s3f6v?rft_dat=source%3Ddrss)  
Erin Carlson, Andrew Northwick, Beza Tuga, Christy Haynes, Rigoberto Hernandez, Yinhan Wang  
*ChemRxiv*  
2025-01-02  
&ensp;The paper investigates protein-nanoparticle interactions, specifically focusing on how proteins like cytochrome c, b-lactoglobulin, and albumin interact with nanoparticles. Using protein footprinting and simulations, it reveals that these proteins bind via flexible loop regions, with localized conformational changes occurring, but significant deformation of secondary structure is unlikely. The study highlights the influence of matrix components on binding orientation.  

- [Free-Energy Landscapes and Surface Dynamics in Methane Activation on Ni(511) via Machine Learning and Enhanced Sampling](https://dx.doi.org/10.26434/chemrxiv-2025-6wnm2?rft_dat=source%3Ddrss)  
Yezhi Jin, Yinan Xu, Jireh Garcia Sanchez, Gustavo Perez-Lemus, Pablo Zubieta Rico, Massimiliano Delferro, Juan de Pablo  
*ChemRxiv*  
2025-01-02  
&ensp;The paper explores methane activation on Ni(511) surfaces using machine-learned interatomic potentials and enhanced sampling techniques. It analyzes how temperature affects the activation process, revealing that dissociation predominantly occurs at step-edge nickel atoms and that increased temperatures lead to shifts in active site preferences. The study provides a detailed understanding of free-energy landscapes and surface dynamics.  

- [An efficient exciton coupling scheme based on simplified time-dependent density functional theory](https://dx.doi.org/10.26434/chemrxiv-2025-d623q?rft_dat=source%3Ddrss)  
Christoph Bannwarth, Mike Pauls, Jan Kubelka, Francesca Plückhahn  
*ChemRxiv*  
2025-01-02  
&ensp;The paper presents an efficient exciton coupling method based on simplified time-dependent density functional theory (sTD-DFT), achieving about 100-fold acceleration in computing electronic absorption and circular dichroism spectra for large molecular aggregates (~10,000 atoms). The method simplifies electrostatic embedding using a dielectric continuum, enhancing computational efficiency for screening photophysical properties. It includes derivations for Tamm-Dancoff and random-phase approximation eigenvalue problems.  

- [Augmented and Programmatically Optimized LLM Prompts Reduce Chemical Hallucinations](https://dx.doi.org/10.26434/chemrxiv-2025-rwgt8?rft_dat=source%3Ddrss)  
Scott Reed  
*ChemRxiv*  
2025-01-02  
&ensp;The paper discusses improving the accuracy of Large Language Models (LLMs) in chemical research by using augmented generation and machine learning-driven prompt optimization. The model predicted the topological polar surface area (TPSA) of molecules, achieving a significant error reduction from 59.41 RMSE to 7.44 RMSE, enhancing LLM performance without custom model training.

## 16 Dec 2024  

- [Inconsistency of LLMs in Molecular Representations](https://dx.doi.org/10.26434/chemrxiv-2024-lnvbz?rft_dat=source%3Ddrss)  
Bing Yan, Angelica Chen, Kyunghyun Cho  
*ChemRxiv*  
2024-12-16  
&ensp;The paper investigates the consistency of large language models (LLMs) in molecular representations like SMILES and IUPAC names. Despite finetuning with a dual representation dataset and applying a Kullback-Leibler divergence loss for training, the models exhibited less than 1% consistency and no improvement in accuracy. Findings highlight the limitations of LLMs in understanding chemistry.  

- [LlaMa meets Cheburashka: impact of cultural background for LLM quiz reasoning](https://dx.doi.org/10.26434/chemrxiv-2024-x78bd?rft_dat=source%3Ddrss)  
Bogdan Protsenko, Mikhail Lifar, Daniil Kupriianenko, Nazar Chubkov, Kirill Kulaev, Alexander Guda, Alexander Soldatov, Irina Piontkovskaya  
*ChemRxiv*  
2024-12-16  
&ensp;The paper investigates the reasoning abilities of the LlaMa3-405B language model in non-English quiz contexts, specifically using questions from the Russian-speaking "What?Where?When?" community. It finds that while the model performs well linguistically, its cultural knowledge is lacking, leading to decreased performance. The study also highlights the significance of reasoning strategies, achieving a 6% accuracy improvement over baseline methods.  

- [PathInHydro, a set of machine learning models to identify unbinding pathways of gas molecules in [NiFe] hydrogenases](https://dx.doi.org/10.26434/chemrxiv-2024-6fb7g-v2?rft_dat=source%3Ddrss)  
Farzin Sohraby, Jing-Yao Guo, Ariane Nunes-Alves  
*ChemRxiv*  
2024-12-16  
&ensp;The paper presents PathInHydro, a machine learning framework for identifying unbinding pathways of gas molecules from [NiFe] hydrogenases using molecular dynamics simulations. Trained on CO and H2 unbinding trajectories from Desulfovibrio fructosovorans, it efficiently analyzes diverse gas molecules and enzyme mutations. The framework enhances data analysis by automating pathway identification, with associated codes and datasets available online.  

- [AlchemBERT: Exploring Lightweight Language Models for Materials Informatics](https://dx.doi.org/10.26434/chemrxiv-2024-r4dnl?rft_dat=source%3Ddrss)  
Xiaotong Liu, Xingchen Liu, Xiaodong Wen  
*ChemRxiv*  
2024-12-16  
&ensp;The paper presents AlchemBERT, a lightweight BERT model (110 million parameters) for materials informatics, demonstrating its effectiveness in predicting material properties using the Matbench dataset. AlchemBERT achieves performance comparable to larger models like GPT and LLaMA, excelling in structure prediction with CIF data. It outperforms state-of-the-art models, indicating fine-tuned LLMs can capture significant material insights.  
